---
title: "Malware detection using Android Permission"
author: "vishesh singhal 20bce1209"
date: "2023-03-08"
output: html_document
---


```{r}
library("dplyr")
library("ggplot2")
library("DataExplorer")
library("caTools")  
library("randomForest") 
library(mlbench)
library(caret)
library(e1071)
```

```{r}

df=read.csv("Android_Permission.csv")
```

```{r}
df2=df[!complete.cases(df),]
nrow(df2)
```

as no of columns with NULL values is so less we can removce them simply

```{r}
df=df[complete.cases(df),]
```

NOW SOME DATA EXPLORATION
```{r}
class=df$Class
class=ifelse(class==1,"Malware","benign")
barplot(table(class),col=c("red","steelblue"),main="malware vs benign distribution",ylab="count of apps",xlab="is malware ")

```

```{r}
df%>%
  ggplot(aes(x=Category))+geom_bar(aes(fill=Category))+facet_wrap(~Class)+labs(title="Category Separation for benign and malware")+
  theme(axis.text.x = element_text(angle=45))
```


```{r}
# Group by category and count malware for each class
cat_malware <- df %>% 
  group_by(Category, Class) %>% 
  summarize(count = n()) %>% 
  mutate(Class = ifelse(Class == 1, "Malware", "Safe"))

# Create stacked bar graph
ggplot(cat_malware, aes(x = Category, y = count, fill = Class)) +
  geom_bar(stat = "identity") + theme(axis.text.x = element_text(angle=45)) +
  labs(title = "Malware vs Safe Apps by Category", x = "Category", y = "Count") +
  theme(plot.title = element_text(hjust = 0.5), legend.position = "bottom") +
  scale_fill_manual(values = c("Malware" = "red", "Safe"="green"))
```

Benign word CLoud

```{r}
# Load required packages
library(tm)
library(SnowballC)
library(wordcloud)

andr.benign <- df %>% filter(Class == 0)
# Read in the data and create a corpus
corpus <- Corpus(VectorSource(df$Description))

# Clean the data
corpus <- tm_map(corpus, tolower)
corpus <- tm_map(corpus, removeNumbers)
corpus <- tm_map(corpus, removePunctuation)
corpus <- tm_map(corpus, removeWords, stopwords("english"))
corpus <- tm_map(corpus, stripWhitespace)
corpus <- tm_map(corpus, stemDocument)

# Create the term-document matrix
tdm <- TermDocumentMatrix(corpus, control = list(minWordLength = 1))

# Remove sparse terms to reduce memory usage
tdm <- removeSparseTerms(tdm, 0.99)

# Get the most frequent words
freq <- sort(rowSums(as.matrix(tdm)), decreasing = TRUE)

# Generate the word cloud
wordcloud(names(freq), freq, max.words = 100, colors = brewer.pal(8, "Dark2"))
```

Malware world cloud

```{r}

andr.benign <- df %>% filter(Class == 1)
# Read in the data and create a corpus
corpus <- Corpus(VectorSource(df$Description))

# Clean the data
corpus <- tm_map(corpus, tolower)
corpus <- tm_map(corpus, removeNumbers)
corpus <- tm_map(corpus, removePunctuation)
corpus <- tm_map(corpus, removeWords, stopwords("english"))
corpus <- tm_map(corpus, stripWhitespace)
corpus <- tm_map(corpus, stemDocument)

# Create the term-document matrix
tdm <- TermDocumentMatrix(corpus, control = list(minWordLength = 1))

# Remove sparse terms to reduce memory usage
tdm <- removeSparseTerms(tdm, 0.99)

# Get the most frequent words
freq <- sort(rowSums(as.matrix(tdm)), decreasing = TRUE)

# Generate the word cloud
wordcloud(names(freq), freq, max.words = 100, colors = brewer.pal(8, "Dark2"))
```


```{r}
library(corrplot)
library(ggplot2)
library(DataExplorer)
plot_correlation(df, theme_config = list(legend.position = "bottom", axis.text.x = ggplot2::element_text(angle=180)))

```

```{r}
df%>%
  ggplot(aes(x=Category,y=Price))+geom_col(aes(fill=Category))+
  facet_wrap(~Class)+labs(title="Category price for benign and malware")+
  theme(axis.text.x = element_text(angle=45))
```

```{r}
set.seed(12342)
split <- sample.split(df, SplitRatio = 0.85)
train <- subset(df, split == "TRUE")
test <- subset(df, split == "FALSE")
```

Neural Network
```{r}
library(neuralnet)
train = select(train, -c(Description,App,Package,Related.apps))
test = select(test, -c(Description,App,Package,Related.apps))
train <- train[, -nearZeroVar(train)]
test <- test[, -nearZeroVar(test)]
train$Category = as.factor(train$Category)
test$Category = as.factor(test$Category)
```


```{r}
train_pca <- prcomp(train[, -1], center = TRUE, scale. = TRUE)
train_pca$x
# Use the first 5 principal components to train the neural network
train_pca_data <- predict(train_pca, train[, -1])
train_pca_data <- as.data.frame(train_pca_data[, 1:8])
train_pca_data$Class <- train$Class
train_pca_data
# Train the neural network
nn <- neuralnet(Class ~ ., 
                data = train_pca_data, 
                hidden = c(2))
plot(nn)
```


```{r}
# Perform PCA on the test data
test_pca_data <- predict(train_pca, test[, -1])
test_pca_data <- as.data.frame(test_pca_data[, 1:8])
test_pca_data$Class <- test$Class

# Make predictions on the test data using the trained neural network
predictions <- predict(nn, test_pca_data[, -1])
predictions[which(predictions>=0.02)] = 1
predictions[which(predictions<0.02)] = 0
confusion_mtx = table(test_pca_data$Class, predictions)
confusion_mtx
plot(confusion_mtx,col="steelblue")
accuracy = sum(predictions == test_pca_data$Class)/nrow(test)
accuracy

```

```{r}
set.seed(12342)
split <- sample.split(df, SplitRatio = 0.85)
train <- subset(df, split == "TRUE")
test <- subset(df, split == "FALSE")
```

```{r}
library(traineR)
library(dplyr)
y = train$Class
X = select(train, -c(Description,App,Package,Related.apps))
lasso.mod <- train.glmnet(Class~.,X)
# Extract coefficient paths for each value of lambda
# coef.paths <- coef(lasso.mod)
#
# # Plot coefficient paths
#
# plot(lasso.mod, xvar = "lambda",label=TRUE)
```


```{r}
X = select(test, -c(Class,Description,App,Package,Related.apps))
y_pred=predict(lasso.mod,X)

table(test$Class,y_pred$prediction)
TreeAccuracy=round(1-mean(y_pred$prediction!=test$Class ) ,3)
print( paste("Accuracy found for data using  GLMFIT is :- ",TreeAccuracy)  );
```


```{r}
X = select(train, -c(Class,Description,App,Package,Related.apps,Category))

pca=prcomp(X)
summary(pca)
screeplot(pca,type="l",npcs=10,main="Scree Plot of PCA values",col="steelblue")
abline(h = 1, col="red", lty=5)
#we need to remove or lessen no of features for better results
#we will remove all columns which contribute very
data=pca$x[,1:5]
data=data.frame(data)
y=train$Class
data=cbind(data,y)

ggplot(data,aes(PC1,PC2,col=y))+geom_point()+stat_ellipse(geom = "polygon",aes(fill=y), alpha = 0.25)
classifer= randomForest(y~.,data=data,ntree=100)

X = select(test, -c(Class,Description,App,Package,Related.apps,Category))

pca=prcomp(X)
testdata=pca$x[,1:5]
testdata=data.frame(testdata)
y=test$Class
testdata=cbind(testdata,y)

summary(classifer)
y_pred = predict(classifer, newdata = testdata[-6] )

y_pred=ifelse(y_pred>0.5,1,0)
confusion_mtx = table(testdata[, 6], y_pred)
confusion_mtx
plot(confusion_mtx,col="steelblue")
TreeAccuracy=round(1-mean(y_pred!=as.factor(testdata[,6]) ) ,3)
print(paste("Accuracy found for data using  randomForest tree is :-",TreeAccuracy));

```


